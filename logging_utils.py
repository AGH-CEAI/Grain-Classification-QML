import os
from typing import List, TextIO
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import mlflow
from pytorch_lightning.loggers import MLFlowLogger
from statistics import mean, stdev
from pytorch_lightning.callbacks import Callback


EXPERIMENT_NAME = "Grain_Seed_Classification"
MLFLOW_URI = "http://localhost:5001"


# ------------------------------------------------------------------------------
# FILE REPORTS
# ------------------------------------------------------------------------------


def print_report_to_file(file: TextIO, model_name: str, y, y_pred):
    file.write(f"\nClassification report for {model_name}:\n")
    file.write(str(classification_report(y, y_pred)))


def print_conf_matrix_to_file(file: TextIO, model_name: str, y, y_pred):
    file.write(f"\nConfusion matrix for {model_name}:\n")
    file.write(str(confusion_matrix(y, y_pred)))


def log_classification_report(model_name: str, y_true, y_pred):
    report = classification_report(y_true, y_pred)
    file_path = f"{model_name}_classification_report.txt"

    with open(file_path, "w") as f:
        f.write(str(report))

    mlflow.log_artifact(file_path)
    os.remove(file_path)


def log_confusion_matrix(model_name: str, y_true, y_pred):
    matrix = confusion_matrix(y_true, y_pred)
    file_path = f"{model_name}_confusion_matrix.txt"

    with open(file_path, "w") as f:
        f.write(np.array2string(matrix))

    mlflow.log_artifact(file_path)
    os.remove(file_path)


# ------------------------------------------------------------------------------
# MLflow Setup
# ------------------------------------------------------------------------------


def setup_mlflow():
    mlflow.set_tracking_uri(MLFLOW_URI)
    mlflow.set_experiment(EXPERIMENT_NAME)


def log_hyperparams(params):
    mlflow.log_params(params)


def start_parent_run(model_name: str):
    run = mlflow.start_run(run_name=model_name)
    mlflow.set_tag("model", model_name)
    return run


def start_child_hp_run(fold_name: str):
    return mlflow.start_run(run_name=fold_name, nested=True)


def log_metrics(metrics: dict):
    for metric_name, values in metrics.items():
        mlflow.log_metric(metric_name, values)


def log_aggregated_metrics(all_fold_metrics: dict):
    for metric_name, values in all_fold_metrics.items():
        mlflow.log_metric(f"{metric_name}_mean", mean(values))
        mlflow.log_metric(f"{metric_name}_std", stdev(values))


# ------------------------------------------------------------------------------
# Callback: Collect + Log Epoch Metrics
# ------------------------------------------------------------------------------


class EpochMetricsTracker(Callback):
    """
    Collects train/val epoch metrics and logs them ONCE per fold.
    This completely removes the need for external log_epochs_metrics().
    """

    def __init__(self):
        super().__init__()
        self.train_epoch_metrics = []
        self.val_epoch_metrics = []

    def on_train_epoch_end(self, trainer, pl_module):
        metrics: dict[str, float | int] = {"epoch": trainer.current_epoch}
        for key, value in trainer.callback_metrics.items():
            if key.startswith("train_"):
                metrics[key] = float(value.item())
        self.train_epoch_metrics.append(metrics)

    def on_validation_epoch_end(self, trainer, pl_module):
        metrics: dict[str, float | int] = {"epoch": trainer.current_epoch}
        for key, value in trainer.callback_metrics.items():
            if key.startswith("val_"):
                metrics[key] = float(value.item())
        self.val_epoch_metrics.append(metrics)

    def on_fit_end(self, trainer, pl_module):
        # Log all epoch metrics at the end of the fold
        for entry in self.train_epoch_metrics + self.val_epoch_metrics:
            epoch = entry["epoch"]
            for k, v in entry.items():
                if k != "epoch":
                    mlflow.log_metric(k, v, step=epoch)

        # Final fold metrics (single values)
        if "val_acc" in trainer.callback_metrics:
            mlflow.log_metric(
                "final_val_acc", float(trainer.callback_metrics["val_acc"])
            )

        if "val_f1" in trainer.callback_metrics:
            mlflow.log_metric("final_val_f1", float(trainer.callback_metrics["val_f1"]))
